{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hT2qDUwCmUmy","outputId":"8d92cd3d-1cfe-4fe5-9737-cacec2181751"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\ProgramData\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import requests\n","from conllu import parse\n","import pandas as pd\n","import torch\n","from transformers import BertTokenizer, BertModel, AutoModelForMaskedLM, AutoModel\n","from transformers import GPT2Tokenizer, GPT2Model\n","from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{"id":"dCxBSAvSmUm2"},"source":["# Attention Head Probing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTzMqGmg2XWE"},"outputs":[],"source":["urls = {\n","    \"dev\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-BOUN/refs/heads/master/tr_boun-ud-dev.conllu\",\n","    \"test\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-BOUN/refs/heads/master/tr_boun-ud-test.conllu\",\n","    \"train\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-BOUN/refs/heads/master/tr_boun-ud-train.conllu\",\n","    \"dev2\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-Atis/refs/heads/master/tr_atis-ud-dev.conllu\",\n","    \"test2\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-Atis/refs/heads/master/tr_atis-ud-test.conllu\",\n","    \"train2\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-Atis/refs/heads/master/tr_atis-ud-train.conllu\",\n","    \"test3\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-GB/refs/heads/master/tr_gb-ud-test.conllu\",\n","    \"dev4\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-Kenet/refs/heads/master/tr_kenet-ud-dev.conllu\",\n","    \"test4\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-Kenet/refs/heads/master/tr_kenet-ud-test.conllu\",\n","    \"train4\": \"https://raw.githubusercontent.com/UniversalDependencies/UD_Turkish-Kenet/refs/heads/master/tr_kenet-ud-train.conllu\"\n","}\n","\n","def fetch_and_parse(url):\n","    response = requests.get(url)\n","    response.raise_for_status()\n","    return parse(response.text)\n","\n","filtered = []\n","for name, url in urls.items():\n","    sentences = fetch_and_parse(url)\n","    for sent in sentences:\n","        nsubj_tokens = [tok for tok in sent if tok[\"deprel\"] == \"nsubj\"]\n","        root_tokens = [tok for tok in sent if tok[\"deprel\"] == \"root\"]\n","        if nsubj_tokens and root_tokens:\n","            filtered.append({\n","                \"sentence\": \" \".join(tok[\"form\"] for tok in sent),\n","                \"nsubj\": [tok[\"form\"] for tok in nsubj_tokens],\n","                \"root\": [tok[\"form\"] for tok in root_tokens],\n","                \"split\": name\n","            })\n","\n","\n","df = pd.DataFrame(filtered)\n","df.to_csv(\"nsubj_root_sentences_tr.csv\", index=False, encoding='utf-8')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6ibgKwzmUm-","outputId":"efaae36f-37e6-4899-b22b-9dbef880987d"},"outputs":[{"ename":"NameError","evalue":"name 'parse' is not defined","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     data = file.read()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Parse the file content\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m parsed_sentences = \u001b[43mparse\u001b[49m(data)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Print the first sentence\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(parsed_sentences[\u001b[32m0\u001b[39m])\n","\u001b[31mNameError\u001b[39m: name 'parse' is not defined"]}],"source":["# Read the CoNLL-U file\n","with open(\"tur_tr_web_2015_1M.conllu\", \"r\", encoding=\"utf-8\") as file:\n","    data = file.read()\n","\n","# Parse the file content\n","parsed_sentences = parse(data)\n","\n","# Print the first sentence\n","print(parsed_sentences[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["95847a6792534459ad7cf1a57298bf8d","b0aec775e9b348a88fd6c10e1183f86c","0fa803c042f14271865de166e3d56ac0","32163483a005491b95ec2cbbb7492c9e","c5d7881866a640dab1ed24cbc4795379","94a2e52eb0664c55a46bbd77fdf5cef8","864b389ff32843109da6fbf7ee9d6446","efa9d48345ba406cb801c5c967897141","1fb76f1bed76497a8dace8c550e8f8e0","d2519c7f49374f8bbfcacb216f2c297c","134334776a3e482bac49ffe97afa431c","c308e926d7ff4065becddf30fec41f70","aea263246a2246109fb369b993f6d0c5","89ee24ab36ab43819fa75d9ee4a94610","aec17f62ae2e4070b35f5d9babdfe970","01ae6b1e92fe4296b33bdcd03a253f65","c23ab283f3c14f4a81587a93e09c20d0","df10ad21684b4af0ae57cb931a2b3fbd","fc915ddbfe984e32b2d470d6721ca312","61ccef3824da4808a35e9a35a4a1578f","647bc58a933a486ea19716726068c40c","fc3f79eb1c92401e97b02ab9f24cf318","3852516f93684934809fb0023a47920d","60f3dafbd12e47d1837da71b2aa825ff","5e26958221d84b7486573d70b8e240cd","3bf0346db9d341a99df3aadec7ddb419","2e0ceb260f90492eab5d90fad20577ce","901cd23124c04d8999caca8b6ef5a76f","40966579997846cf9460c09d2eabc649","88e6592fb0ee440e8c040c75f9de2786","f275096eb13b430fabda34c6775c4a10","70175c3af1a844038a8977dadbba96e8","c6a8ad9b2fdf480da4c2deebf4f93f65","90ab314d128f4cb58037d5ea9349d74f","f5d81ab61c414e33bc834914919cbda5","6c2d512ed0ca49048a51e40f621a57cd","371d0b936b1847c5b80f53e7b2c34414","4172e6c05f364f21b272163eb4f7e673","f6745bf2bcd044aa93a6ae660826efba","4fc815bd7ba2491cb3d699d610626b8d","a131c1ebbee84fc5ab3c68eb10ae8772","a68c7567b1cc430baa8274b0a77efb14","1a803b3bff2049bb8351e780bfa0887b","27e71a54bfe2418792952b481b5193ee"]},"id":"SqVN0yAw3Gwt","outputId":"d2ecf233-d6bb-4572-95eb-845b788162b1"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m attentions = outputs.attentions\n\u001b[32m     31\u001b[39m attn_tensor = torch.stack(attentions).squeeze(\u001b[32m1\u001b[39m)\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:588\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    585\u001b[39m     attention_output = cross_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    586\u001b[39m     outputs = outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m588\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:596\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    595\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:512\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[31mKeyboardInterrupt\u001b[39m: "]}],"source":["model_name = \"dbmdz/bert-base-turkish-128k-cased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertModel.from_pretrained(model_name, output_attentions=True)\n","model.eval()\n","\n","df = pd.read_csv(\"nsubj_root_sentences_tr.csv\")\n","\n","results = []\n","\n","for i, row in df.iterrows():\n","    sentence = row[\"sentence\"]\n","    nsubj = row[\"nsubj\"].strip(\"[]'\").split(\",\")[0].strip()\n","    root = row[\"root\"].strip(\"[]'\").split(\",\")[0].strip()\n","\n","    inputs = tokenizer(sentence, return_tensors=\"pt\")\n","    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n","\n","    try:\n","        nsubj_idx = tokens.index(nsubj)\n","        root_idx = tokens.index(root)\n","    except ValueError:\n","        continue\n","\n","    if root_idx < nsubj_idx:\n","        continue\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs, output_attentions=True)\n","\n","    attentions = outputs.attentions\n","    attn_tensor = torch.stack(attentions).squeeze(1)\n","    attention_scores = attn_tensor[:, :, root_idx, nsubj_idx]\n","\n","    flat_idx = torch.argmax(attention_scores)\n","    best_layer = flat_idx.item() // attention_scores.shape[1]\n","    best_head = flat_idx.item() % attention_scores.shape[1]\n","    max_value = attention_scores[best_layer, best_head].item()\n","\n","    results.append({\n","        \"sentence\": sentence,\n","        \"nsubj\": nsubj,\n","        \"root\": root,\n","        \"nsubj_idx\": nsubj_idx,\n","        \"root_idx\": root_idx,\n","        \"best_layer\": best_layer,\n","        \"best_head\": best_head,\n","        \"attention_value\": max_value\n","    })\n","\n","pd.DataFrame(results).to_csv(\"turkish_bert_attention_nsubj_root.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PjEKh8P5_6o"},"outputs":[],"source":["model_name = \"redrussianarmy/gpt2-turkish-cased\"\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","model = GPT2Model.from_pretrained(model_name, output_attentions=True)\n","model.eval()\n","\n","df = pd.read_csv(\"nsubj_root_sentences_tr.csv\")\n","\n","results = []\n","\n","for i, row in df.iterrows():\n","    sentence = row[\"sentence\"]\n","    nsubj = row[\"nsubj\"].strip(\"[]'\").split(\",\")[0].strip()\n","    root = row[\"root\"].strip(\"[]'\").split(\",\")[0].strip()\n","\n","    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True)\n","    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n","\n","    try:\n","        root_idxs = [i for i, tok in enumerate(tokens) if root in tok]\n","        nsubj_idxs = [i for i, tok in enumerate(tokens) if nsubj in tok]\n","        if not root_idxs or not nsubj_idxs:\n","            continue\n","        root_idx = root_idxs[0]\n","        nsubj_idx = nsubj_idxs[0]\n","        if nsubj_idx >= root_idx:\n","            continue\n","    except Exception:\n","        continue\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs, output_attentions=True)\n","\n","    attentions = outputs.attentions\n","    attn_tensor = torch.stack(attentions).squeeze(1)\n","\n","    attention_scores = attn_tensor[:, :, root_idx, nsubj_idx]\n","\n","    flat_idx = torch.argmax(attention_scores)\n","    best_layer = flat_idx.item() // attention_scores.shape[1]\n","    best_head = flat_idx.item() % attention_scores.shape[1]\n","    max_value = attention_scores[best_layer, best_head].item()\n","\n","    results.append({\n","        \"sentence\": sentence,\n","        \"nsubj\": nsubj,\n","        \"root\": root,\n","        \"root_idx\": root_idx,\n","        \"nsubj_idx\": nsubj_idx,\n","        \"best_layer\": best_layer,\n","        \"best_head\": best_head,\n","        \"attention_value\": max_value\n","    })\n","\n","pd.DataFrame(results).to_csv(\"gpt2_turkish_attention_nsubj_root.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LVSzztsmChyy"},"outputs":[],"source":["def summarize_attention_weight(csv_path):\n","    df = pd.read_csv(csv_path)\n","    total_sentences = len(df)\n","\n","    weighted_scores = (\n","        df.groupby([\"best_layer\", \"best_head\"])[\"attention_value\"]\n","        .sum()\n","        .reset_index()\n","        .rename(columns={\"attention_value\": \"total_weighted_attention\"})\n","    )\n","\n","    frequency = (\n","        df.groupby([\"best_layer\", \"best_head\"])\n","        .size()\n","        .reset_index(name=\"count\")\n","    )\n","\n","    summary = weighted_scores.merge(frequency, on=[\"best_layer\", \"best_head\"])\n","    summary[\"percentage\"] = 100 * summary[\"count\"] / total_sentences\n","\n","    top5 = summary.sort_values(\"total_weighted_attention\", ascending=False).head(5)\n","    return top5\n","\n","\n","def summarize_attention_frequency(csv_path):\n","    df = pd.read_csv(csv_path)\n","    total = len(df)\n","\n","    freq_table = (\n","        df.groupby([\"best_layer\", \"best_head\"])\n","        .size()\n","        .reset_index(name=\"count\")\n","        .sort_values(\"count\", ascending=False)\n","    )\n","    freq_table[\"percentage\"] = 100 * freq_table[\"count\"] / total\n","\n","    return freq_table.head(5)\n","\n","def get_top_layer_head(df, myrow=\"total_weighted_attention\"):\n","    top_row = df.loc[df[myrow].idxmax()]\n","    LAYER = int(top_row[\"layer\"])\n","    HEAD = int(top_row[\"head\"])\n","    return LAYER, HEAD\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msok3UTp6NsQ","outputId":"2e1aaf3b-a3f9-49c2-b2c4-d70633c450a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["   model  layer  head  correct   total  accuracy\n","66  gpt2      5     6   162764  377269  0.431427\n","60  gpt2      5     0   161705  377269  0.428620\n","68  gpt2      5     8   159902  377269  0.423841\n","61  gpt2      5     1   129968  377269  0.344497\n","27  gpt2      2     3   128082  377269  0.339498\n"]}],"source":["gpt2_voita_head_accuracy_df = pd.read_csv(\"./Transformers/results/gpt2_voita_head_accuracy_full.csv\")\n","\n","top_5_gpt = gpt2_voita_head_accuracy_df.nlargest(5, 'accuracy')\n","\n","print(top_5_gpt)\n","\n","GPT2_LAYER, GPT2_HEAD = get_top_layer_head(top_5_gpt, 'accuracy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vd3z14it6PnK","outputId":"fd6b466a-b499-491c-88f4-c29163193c9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["   model  layer  head  correct   total  accuracy\n","71  bert      5    11   104757  377253  0.277684\n","51  bert      4     3    94316  377253  0.250007\n","87  bert      7     3    85286  377253  0.226071\n","92  bert      7     8    69350  377253  0.183829\n","78  bert      6     6    68380  377253  0.181258\n"]}],"source":["bert_voita_head_accuracy_df = pd.read_csv(\"./Transformers/results/bert_voita_head_accuracy_full.csv\")\n","\n","top_5_bert = bert_voita_head_accuracy_df.nlargest(5, 'accuracy')\n","\n","print(top_5_bert)\n","\n","BERT_LAYER, BERT_HEAD = get_top_layer_head(top_5_bert, 'accuracy')"]},{"cell_type":"markdown","metadata":{"id":"caxtznLCmUnA"},"source":["# Attention"]},{"cell_type":"markdown","metadata":{"id":"E8cSM_UdmUnA"},"source":["## GPT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RaUx_xNH60MS","outputId":"cec3ef41-fea1-4bb6-9657-12f1c40ace0c"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"name":"stdout","output_type":"stream","text":["göç\n","menin\n","göç\n","menin\n","sözcü\n","leri\n","göç\n","menin\n","sözcü\n","leri\n","geçen\n","hafta\n","protest\n","oda\n","aralıksız\n","bağır\n","dılar\n","göç\n","men\n","lerin\n","göç\n","men\n","lerin\n","sözcüsü\n","göç\n","men\n","lerin\n","sözcüsü\n","geçen\n","hafta\n","protest\n","oda\n","aralıksız\n","bağır\n","dılar\n","göç\n","menin\n","göç\n","menin\n","sözcüsü\n","göç\n","menin\n","sözcüsü\n","geçen\n","hafta\n","protest\n","oda\n","aralıksız\n","bağır\n","dılar\n","göç\n","men\n","göç\n","men\n","sözcü\n","leri\n","göç\n","men\n","sözcü\n","leri\n","geçen\n","hafta\n","protest\n","oda\n","aralıksız\n","bağır\n","dılar\n","göç\n","menler\n","göç\n","menler\n","sözcüsü\n","göç\n","menler\n","sözcüsü\n","geçen\n","hafta\n","protest\n","oda\n","aralıksız\n","bağır\n","dılar\n","göç\n","men\n","göç\n","men\n","sözcüsü\n","göç\n","men\n","sözcüsü\n","geçen\n","hafta\n","protest\n","oda\n","aralıksız\n","bağır\n","dılar\n","s\n","taj\n","yer\n","in\n","s\n","taj\n","yer\n","in\n","temsilcileri\n","s\n","taj\n","yer\n","in\n","temsilcileri\n","bugünkü\n","toplantıda\n","edep\n","siz\n","edep\n","siz\n","konuştu\n","lar\n","s\n","taj\n","yer\n","lerin\n","s\n","taj\n","yer\n","lerin\n","temsilcisi\n","s\n","taj\n","yer\n","lerin\n","temsilcisi\n","bugünkü\n","toplantıda\n","edep\n","siz\n","edep\n","siz\n","konuştu\n","lar\n","s\n","taj\n","yer\n","in\n","s\n","taj\n","yer\n","in\n","temsilcisi\n","s\n","taj\n","yer\n","in\n","temsilcisi\n","bugünkü\n","toplantıda\n","edep\n","siz\n","edep\n","siz\n","konuştu\n","lar\n","s\n","taj\n","yer\n","s\n","taj\n","yer\n","temsilcileri\n","s\n","taj\n","yer\n","temsilcileri\n","bugünkü\n","toplantıda\n","edep\n","siz\n","edep\n","siz\n","konuştu\n","lar\n","s\n","taj\n","y\n","erler\n","s\n","taj\n","y\n","erler\n","temsilcisi\n","s\n","taj\n","y\n","erler\n","temsilcisi\n","bugünkü\n","toplantıda\n","edep\n","siz\n","edep\n","siz\n","konuştu\n","lar\n","s\n","taj\n","yer\n","s\n","taj\n","yer\n","temsilcisi\n","s\n","taj\n","yer\n","temsilcisi\n","bugünkü\n","toplantıda\n","edep\n","siz\n","edep\n","siz\n","konuştu\n","lar\n","esnaf\n","ın\n","esnaf\n","ın\n","yöneticileri\n","esnaf\n","ın\n","yöneticileri\n","seçimden\n","sonra\n","sen\n","at\n","oda\n","sert\n","çe\n","tartış\n","tılar\n","esnaf\n","ların\n","esnaf\n","ların\n","yöneticisi\n","esnaf\n","ların\n","yöneticisi\n","seçimden\n","sonra\n","sen\n","at\n","oda\n","sert\n","çe\n","tartış\n","tılar\n","esnaf\n","ın\n","esnaf\n","ın\n","yöneticisi\n","esnaf\n","ın\n","yöneticisi\n","seçimden\n","sonra\n","sen\n","at\n","oda\n","sert\n","çe\n","tartış\n","tılar\n","esnaf\n","esnaf\n","yöneticileri\n","esnaf\n","yöneticileri\n","seçimden\n","sonra\n","sen\n","at\n","oda\n","sert\n","çe\n","tartış\n","tılar\n","esnaf\n","lar\n","esnaf\n","lar\n","yöneticisi\n","esnaf\n","lar\n","yöneticisi\n","seçimden\n","sonra\n","sen\n","at\n","oda\n","sert\n","çe\n","tartış\n","tılar\n","esnaf\n","esnaf\n","yöneticisi\n","esnaf\n","yöneticisi\n","seçimden\n","sonra\n","sen\n","at\n","oda\n","sert\n","çe\n","tartış\n","tılar\n","m\n","ült\n","ecinin\n","m\n","ült\n","ecinin\n","avukatları\n","m\n","ült\n","ecinin\n","avukatları\n","duruşma\n","için\n","uzun\n","süre\n","hazırlandı\n","lar\n","m\n","ült\n","ecilerin\n","m\n","ült\n","ecilerin\n","avukatı\n","m\n","ült\n","ecilerin\n","avukatı\n","duruşma\n","için\n","uzun\n","süre\n","hazırlandı\n","lar\n","m\n","ült\n","ecinin\n","m\n","ült\n","ecinin\n","avukatı\n","m\n","ült\n","ecinin\n","avukatı\n","duruşma\n","için\n","uzun\n","süre\n","hazırlandı\n","lar\n","m\n","ült\n","eci\n","m\n","ült\n","eci\n","avukatları\n","m\n","ült\n","eci\n","avukatları\n","duruşma\n","için\n","uzun\n","süre\n","hazırlandı\n","lar\n","m\n","ült\n","eciler\n","m\n","ült\n","eciler\n","avukatı\n","m\n","ült\n","eciler\n","avukatı\n","duruşma\n","için\n","uzun\n","süre\n","hazırlandı\n","lar\n","m\n","ült\n","eci\n","m\n","ült\n","eci\n","avukatı\n","m\n","ült\n","eci\n","avukatı\n","duruşma\n","için\n","uzun\n","süre\n","hazırlandı\n","lar\n","p\n","adişah\n","ın\n","p\n","adişah\n","ın\n","tarih\n","çileri\n","p\n","adişah\n","ın\n","tarih\n","çileri\n","yolculuk\n","için\n","yavaşça\n","tren\n","e\n","bin\n","diler\n","p\n","adişah\n","ların\n","p\n","adişah\n","ların\n","tarih\n","çisi\n","p\n","adişah\n","ların\n","tarih\n","çisi\n","yolculuk\n","için\n","yavaşça\n","tren\n","e\n","bin\n","diler\n","p\n","adişah\n","ın\n","p\n","adişah\n","ın\n","tarih\n","çisi\n","p\n","adişah\n","ın\n","tarih\n","çisi\n","yolculuk\n","için\n","yavaşça\n","tren\n","e\n","bin\n","diler\n","p\n","adişah\n","p\n","adişah\n","tarih\n","çileri\n","p\n","adişah\n","tarih\n","çileri\n","yolculuk\n","için\n","yavaşça\n","tren\n","e\n","bin\n","diler\n","p\n","adişah\n","lar\n","p\n","adişah\n","lar\n","tarih\n","çisi\n","p\n","adişah\n","lar\n","tarih\n","çisi\n","yolculuk\n","için\n","yavaşça\n","tren\n","e\n","bin\n","diler\n","p\n","adişah\n","p\n","adişah\n","tarih\n","çisi\n","p\n","adişah\n","tarih\n","çisi\n","yolculuk\n","için\n","yavaşça\n","tren\n","e\n","bin\n","diler\n","mar\n","angoz\n","un\n","mar\n","angoz\n","un\n","ustaları\n","mar\n","angoz\n","un\n","ustaları\n","çoktan\n","\n","yeni\n","semt\n","teki\n","atöly\n","eye\n","ulaş\n","mışlar\n","mar\n","angoz\n","ların\n","mar\n","angoz\n","ların\n","ustası\n","mar\n","angoz\n","ların\n","ustası\n","çoktan\n","\n","yeni\n","semt\n","teki\n","atöly\n","eye\n","ulaş\n","mışlar\n","mar\n","angoz\n","un\n","mar\n","angoz\n","un\n","ustası\n","mar\n","angoz\n","un\n","ustası\n","çoktan\n","\n","yeni\n","semt\n","teki\n","atöly\n","eye\n","ulaş\n","mışlar\n","mar\n","angoz\n","mar\n","angoz\n","ustaları\n","mar\n","angoz\n","ustaları\n","çoktan\n","\n","yeni\n","semt\n","teki\n","atöly\n","eye\n","ulaş\n","mışlar\n","mar\n","angoz\n","lar\n","mar\n","angoz\n","lar\n","ustası\n","mar\n","angoz\n","lar\n","ustası\n","çoktan\n","\n","yeni\n","semt\n","teki\n","atöly\n","eye\n","ulaş\n","mışlar\n","mar\n","angoz\n","mar\n","angoz\n","ustası\n","mar\n","angoz\n","ustası\n","çoktan\n","\n","yeni\n","semt\n","teki\n","atöly\n","eye\n","ulaş\n","mışlar\n","bak\n","anın\n","bak\n","anın\n","sekret\n","erleri\n","bak\n","anın\n","sekret\n","erleri\n","utanç\n","içinde\n","koridor\n","daki\n","kapıya\n","yönel\n","diler\n","bak\n","anların\n","bak\n","anların\n","sekret\n","eri\n","bak\n","anların\n","sekret\n","eri\n","utanç\n","içinde\n","koridor\n","daki\n","kapıya\n","yönel\n","diler\n","bak\n","anın\n","bak\n","anın\n","sekret\n","eri\n","bak\n","anın\n","sekret\n","eri\n","utanç\n","içinde\n","koridor\n","daki\n","kapıya\n","yönel\n","diler\n","bakan\n","bakan\n","sekret\n","erleri\n","bakan\n","sekret\n","erleri\n","utanç\n","içinde\n","koridor\n","daki\n","kapıya\n","yönel\n","diler\n","bak\n","anlar\n","bak\n","anlar\n","sekret\n","eri\n","bak\n","anlar\n","sekret\n","eri\n","utanç\n","içinde\n","koridor\n","daki\n","kapıya\n","yönel\n","diler\n","bakan\n","bakan\n","sekret\n","eri\n","bakan\n","sekret\n","eri\n","utanç\n","içinde\n","koridor\n","daki\n","kapıya\n","yönel\n","diler\n","oy\n","unc\n","unun\n","oy\n","unc\n","unun\n","koç\n","ları\n","oy\n","unc\n","unun\n","koç\n","ları\n","ertesi\n","gün\n","prov\n","aya\n","geç\n","geldiler\n","oyuncu\n","ların\n","oyuncu\n","ların\n","koçu\n","oyuncu\n","ların\n","koçu\n","ertesi\n","gün\n","prov\n","aya\n","geç\n","geldiler\n","oy\n","unc\n","unun\n","oy\n","unc\n","unun\n","koçu\n","oy\n","unc\n","unun\n","koçu\n","ertesi\n","gün\n","prov\n","aya\n","geç\n","geldiler\n","oyuncu\n","oyuncu\n","koç\n","ları\n","oyuncu\n","koç\n","ları\n","ertesi\n","gün\n","prov\n","aya\n","geç\n","geldiler\n","oyuncular\n","oyuncular\n","koçu\n","oyuncular\n","koçu\n","ertesi\n","gün\n","prov\n","aya\n","geç\n","geldiler\n","oyuncu\n","oyuncu\n","koçu\n","oyuncu\n","koçu\n","ertesi\n","gün\n","prov\n","aya\n","geç\n","geldiler\n","yatırım\n","cının\n","yatırım\n","cının\n","danışmanları\n","yatırım\n","cının\n","danışmanları\n","dönem\n","sonundaki\n","toplantı\n","dan\n","öfkeyle\n","çıktılar\n","yatırım\n","cıların\n","yatırım\n","cıların\n","danışmanı\n","yatırım\n","cıların\n","danışmanı\n","dönem\n","sonundaki\n","toplantı\n","dan\n","öfkeyle\n","çıktılar\n","yatırım\n","cının\n","yatırım\n","cının\n","danışmanı\n","yatırım\n","cının\n","danışmanı\n","dönem\n","sonundaki\n","toplantı\n","dan\n","öfkeyle\n","çıktılar\n","yatırım\n","cı\n","yatırım\n","cı\n","danışmanları\n","yatırım\n","cı\n","danışmanları\n","dönem\n","sonundaki\n","toplantı\n","dan\n","öfkeyle\n","çıktılar\n","yatırım\n","cılar\n","yatırım\n","cılar\n","danışmanı\n","yatırım\n","cılar\n","danışmanı\n","dönem\n","sonundaki\n","toplantı\n","dan\n","öfkeyle\n","çıktılar\n","yatırım\n","cı\n","yatırım\n","cı\n","danışmanı\n","yatırım\n","cı\n","danışmanı\n","dönem\n","sonundaki\n","toplantı\n","dan\n","öfkeyle\n","çıktılar\n","m\n","ült\n","ecinin\n","m\n","ült\n","ecinin\n","dostları\n","m\n","ült\n","ecinin\n","dostları\n","savaşın\n","ardından\n","yardım\n","çağrısına\n","koştu\n","lar\n","m\n","ült\n","ecilerin\n","m\n","ült\n","ecilerin\n","dostu\n","m\n","ült\n","ecilerin\n","dostu\n","savaşın\n","ardından\n","yardım\n","çağrısına\n","koştu\n","lar\n","m\n","ült\n","ecinin\n","m\n","ült\n","ecinin\n","dostu\n","m\n","ült\n","ecinin\n","dostu\n","savaşın\n","ardından\n","yardım\n","çağrısına\n","koştu\n","lar\n","m\n","ült\n","eci\n","m\n","ült\n","eci\n","dostları\n","m\n","ült\n","eci\n","dostları\n","savaşın\n","ardından\n","yardım\n","çağrısına\n","koştu\n","lar\n","m\n","ült\n","eciler\n","m\n","ült\n","eciler\n","dostu\n","m\n","ült\n","eciler\n","dostu\n","savaşın\n","ardından\n","yardım\n","çağrısına\n","koştu\n","lar\n","m\n","ült\n","eci\n","m\n","ült\n","eci\n","dostu\n","m\n","ült\n","eci\n","dostu\n","savaşın\n","ardından\n","yardım\n","çağrısına\n","koştu\n","lar\n","sen\n","dik\n","acının\n","sen\n","dik\n","acının\n","vekil\n","leri\n","sen\n","dik\n","acının\n","vekil\n","leri\n","görüşme\n","salon\n","undan\n","hızlı\n","hızlı\n","uzaklaş\n","tılar\n","sen\n","dik\n","acıların\n","sen\n","dik\n","acıların\n","vekili\n","sen\n","dik\n","acıların\n","vekili\n","görüşme\n","salon\n","undan\n","hızlı\n","hızlı\n","uzaklaş\n","tılar\n","sen\n","dik\n","acının\n","sen\n","dik\n","acının\n","vekili\n","sen\n","dik\n","acının\n","vekili\n","görüşme\n","salon\n","undan\n","hızlı\n","hızlı\n","uzaklaş\n","tılar\n","sen\n","dik\n","acı\n","sen\n","dik\n","acı\n","vekil\n","leri\n","sen\n","dik\n","acı\n","vekil\n","leri\n","görüşme\n","salon\n","undan\n","hızlı\n","hızlı\n","uzaklaş\n","tılar\n","sen\n","dik\n","acılar\n","sen\n","dik\n","acılar\n","vekili\n","sen\n","dik\n","acılar\n","vekili\n","görüşme\n","salon\n","undan\n","hızlı\n","hızlı\n","uzaklaş\n","tılar\n","sen\n","dik\n","acı\n","sen\n","dik\n","acı\n","vekili\n","sen\n","dik\n","acı\n","vekili\n","görüşme\n","salon\n","undan\n","hızlı\n","hızlı\n","uzaklaş\n","tılar\n","mem\n","urun\n","mem\n","urun\n","düşmanları\n","mem\n","urun\n","düşmanları\n","kavg\n","anın\n","ortasında\n","aniden\n","habersiz\n","ce\n","kaç\n","tılar\n","memur\n","ların\n","memur\n","ların\n","düşmanı\n","memur\n","ların\n","düşmanı\n","kavg\n","anın\n","ortasında\n","aniden\n","habersiz\n","ce\n","kaç\n","tılar\n","mem\n","urun\n","mem\n","urun\n","düşmanı\n","mem\n","urun\n","düşmanı\n","kavg\n","anın\n","ortasında\n","aniden\n","habersiz\n","ce\n","kaç\n","tılar\n","memur\n","memur\n","düşmanları\n","memur\n","düşmanları\n","kavg\n","anın\n","ortasında\n","aniden\n","habersiz\n","ce\n","kaç\n","tılar\n","mem\n","urlar\n","mem\n","urlar\n","düşmanı\n","mem\n","urlar\n","düşmanı\n","kavg\n","anın\n","ortasında\n","aniden\n","habersiz\n","ce\n","kaç\n","tılar\n","memur\n","memur\n","düşmanı\n","memur\n","düşmanı\n","kavg\n","anın\n","ortasında\n","aniden\n","habersiz\n","ce\n","kaç\n","tılar\n","suç\n","lunun\n","suç\n","lunun\n","av\n","cıları\n","suç\n","lunun\n","av\n","cıları\n","son\n","çatışmada\n","dikkat\n","sizlik\n","yüzünden\n","yaralan\n","dılar\n","suç\n","lu\n","ların\n","suç\n","lu\n","ların\n","av\n","cısı\n","suç\n","lu\n","ların\n","av\n","cısı\n","son\n","çatışmada\n","dikkat\n","sizlik\n","yüzünden\n","yaralan\n","dılar\n","suç\n","lunun\n","suç\n","lunun\n","av\n","cısı\n","suç\n","lunun\n","av\n","cısı\n","son\n","çatışmada\n","dikkat\n","sizlik\n","yüzünden\n","yaralan\n","dılar\n","suç\n","lu\n","suç\n","lu\n","av\n","cıları\n","suç\n","lu\n","av\n","cıları\n","son\n","çatışmada\n","dikkat\n","sizlik\n","yüzünden\n","yaralan\n","dılar\n","suç\n","lular\n","suç\n","lular\n","av\n","cısı\n","suç\n","lular\n","av\n","cısı\n","son\n","çatışmada\n","dikkat\n","sizlik\n","yüzünden\n","yaralan\n","dılar\n","suç\n","lu\n","suç\n","lu\n","av\n","cısı\n","suç\n","lu\n","av\n","cısı\n","son\n","çatışmada\n","dikkat\n","sizlik\n","yüzünden\n","yaralan\n","dılar\n","sen\n","dik\n","acının\n","sen\n","dik\n","acının\n","koordin\n","atörleri\n","sen\n","dik\n","acının\n","koordin\n","atörleri\n","yarın\n","ki\n","önemli\n","görüşme\n","için\n","hazırlandı\n","lar\n","sen\n","dik\n","acıların\n","sen\n","dik\n","acıların\n","koordin\n","atörü\n","sen\n","dik\n","acıların\n","koordin\n","atörü\n","yarın\n","ki\n","önemli\n","görüşme\n","için\n","hazırlandı\n","lar\n","sen\n","dik\n","acının\n","sen\n","dik\n","acının\n","koordin\n","atörü\n","sen\n","dik\n","acının\n","koordin\n","atörü\n","yarın\n","ki\n","önemli\n","görüşme\n","için\n","hazırlandı\n","lar\n","sen\n","dik\n","acı\n","sen\n","dik\n","acı\n","koordin\n","atörleri\n","sen\n","dik\n","acı\n","koordin\n","atörleri\n","yarın\n","ki\n","önemli\n","görüşme\n","için\n","hazırlandı\n","lar\n","sen\n","dik\n","acılar\n","sen\n","dik\n","acılar\n","koordin\n","atörü\n","sen\n","dik\n","acılar\n","koordin\n","atörü\n","yarın\n","ki\n","önemli\n","görüşme\n","için\n","hazırlandı\n","lar\n","sen\n","dik\n","acı\n","sen\n","dik\n","acı\n","koordin\n","atörü\n","sen\n","dik\n","acı\n","koordin\n","atörü\n","yarın\n","ki\n","önemli\n","görüşme\n","için\n","hazırlandı\n","lar\n","engel\n","linin\n","engel\n","linin\n","bakıcı\n","ları\n","engel\n","linin\n","bakıcı\n","ları\n","uf\n","acık\n","zam\n","ma\n","anlamsız\n","ca\n","çok\n","sev\n","ind\n","iler\n","engel\n","lilerin\n","engel\n","lilerin\n","bak\n","ıcısı\n","engel\n","lilerin\n","bak\n","ıcısı\n","uf\n","acık\n","zam\n","ma\n","anlamsız\n","ca\n","çok\n","sev\n","ind\n","iler\n","engel\n","linin\n","engel\n","linin\n","bak\n","ıcısı\n","engel\n","linin\n","bak\n","ıcısı\n","uf\n","acık\n","zam\n","ma\n","anlamsız\n","ca\n","çok\n","sev\n","ind\n","iler\n","engelli\n","engelli\n","bakıcı\n","ları\n","engelli\n","bakıcı\n","ları\n","uf\n","acık\n","zam\n","ma\n","anlamsız\n","ca\n","çok\n","sev\n","ind\n","iler\n","engel\n","liler\n","engel\n","liler\n","bak\n","ıcısı\n","engel\n","liler\n","bak\n","ıcısı\n","uf\n","acık\n","zam\n","ma\n","anlamsız\n","ca\n","çok\n","sev\n","ind\n","iler\n","engelli\n","engelli\n","bak\n","ıcısı\n","engelli\n","bak\n","ıcısı\n","uf\n","acık\n","zam\n","ma\n","anlamsız\n","ca\n","çok\n","sev\n","ind\n","iler\n","part\n","ner\n","in\n","part\n","ner\n","in\n","terap\n","istleri\n","part\n","ner\n","in\n","terap\n","istleri\n","zor\n","durum\n","karşısında\n","ihtiyat\n","lı\n","davran\n","dılar\n","part\n","ner\n","lerin\n","part\n","ner\n","lerin\n","terap\n","isti\n","part\n","ner\n","lerin\n","terap\n","isti\n","zor\n","durum\n","karşısında\n","ihtiyat\n","lı\n","davran\n","dılar\n","part\n","ner\n","in\n","part\n","ner\n","in\n","terap\n","isti\n","part\n","ner\n","in\n","terap\n","isti\n","zor\n","durum\n","karşısında\n","ihtiyat\n","lı\n","davran\n","dılar\n","part\n","ner\n","part\n","ner\n","terap\n","istleri\n","part\n","ner\n","terap\n","istleri\n","zor\n","durum\n","karşısında\n","ihtiyat\n","lı\n","davran\n","dılar\n","part\n","n\n","erler\n","part\n","n\n","erler\n","terap\n","isti\n","part\n","n\n","erler\n","terap\n","isti\n","zor\n","durum\n","karşısında\n","ihtiyat\n","lı\n","davran\n","dılar\n","part\n","ner\n","part\n","ner\n","terap\n","isti\n","part\n","ner\n","terap\n","isti\n","zor\n","durum\n","karşısında\n","ihtiyat\n","lı\n","davran\n","dılar\n","spor\n","cunun\n","spor\n","cunun\n","eğitmen\n","leri\n","spor\n","cunun\n","eğitmen\n","leri\n","yoğun\n","hazırlık\n","döneminden\n","\n","sonra\n","yor\n","uldu\n","lar\n","spor\n","cuların\n","spor\n","cuların\n","eğit\n","meni\n","spor\n","cuların\n","eğit\n","meni\n","yoğun\n","hazırlık\n","döneminden\n","\n","sonra\n","yor\n","uldu\n","lar\n","spor\n","cunun\n","spor\n","cunun\n","eğit\n","meni\n","spor\n","cunun\n","eğit\n","meni\n","yoğun\n","hazırlık\n","döneminden\n","\n","sonra\n","yor\n","uldu\n","lar\n","spor\n","cu\n","spor\n","cu\n","eğitmen\n","leri\n","spor\n","cu\n","eğitmen\n","leri\n","yoğun\n","hazırlık\n","döneminden\n","\n","sonra\n","yor\n","uldu\n","lar\n","spor\n","cular\n","spor\n","cular\n","eğit\n","meni\n","spor\n","cular\n","eğit\n","meni\n","yoğun\n","hazırlık\n","döneminden\n","\n","sonra\n","yor\n","uldu\n","lar\n","spor\n","cu\n","spor\n","cu\n","eğit\n","meni\n","spor\n","cu\n","eğit\n","meni\n","yoğun\n","hazırlık\n","döneminden\n","\n","sonra\n","yor\n","uldu\n","lar\n","i̇ş\n","çinin\n","i̇ş\n","çinin\n","\n","sorumlu\n","ları\n","i̇ş\n","çinin\n","\n","sorumlu\n","ları\n","soğuk\n","kış\n","hav\n","asından\n","ötürü\n","hastalan\n","dılar\n","i̇ş\n","çilerin\n","i̇ş\n","çilerin\n","sorumlusu\n","i̇ş\n","çilerin\n","sorumlusu\n","soğuk\n","kış\n","hav\n","asından\n","ötürü\n","hastalan\n","dılar\n","i̇ş\n","çinin\n","i̇ş\n","çinin\n","\n","sorumlusu\n","i̇ş\n","çinin\n","\n","sorumlusu\n","soğuk\n","kış\n","hav\n","asından\n","ötürü\n","hastalan\n","dılar\n","i̇şçi\n","i̇şçi\n","sorumlu\n","ları\n","i̇şçi\n","sorumlu\n","ları\n","soğuk\n","kış\n","hav\n","asından\n","ötürü\n","hastalan\n","dılar\n","i̇ş\n","çiler\n","i̇ş\n","çiler\n","sorumlusu\n","i̇ş\n","çiler\n","sorumlusu\n","soğuk\n","kış\n","hav\n","asından\n","ötürü\n","hastalan\n","dılar\n","i̇şçi\n","i̇şçi\n","sorumlusu\n","i̇şçi\n","sorumlusu\n","soğuk\n","kış\n","hav\n","asından\n","ötürü\n","hastalan\n","dılar\n","bank\n","acının\n","bank\n","acının\n","anal\n","istleri\n","bank\n","acının\n","anal\n","istleri\n","büyük\n","ölçekte\n","veri\n","karşısında\n","zor\n","landı\n","lar\n","bank\n","acıların\n","bank\n","acıların\n","anal\n","isti\n","bank\n","acıların\n","anal\n","isti\n","büyük\n","ölçekte\n","veri\n","karşısında\n","zor\n","landı\n","lar\n","bank\n","acının\n","bank\n","acının\n","anal\n","isti\n","bank\n","acının\n","anal\n","isti\n","büyük\n","ölçekte\n","veri\n","karşısında\n","zor\n","landı\n","lar\n","bank\n","acı\n","bank\n","acı\n","anal\n","istleri\n","bank\n","acı\n","anal\n","istleri\n","büyük\n","ölçekte\n","veri\n","karşısında\n","zor\n","landı\n","lar\n","bank\n","acılar\n","bank\n","acılar\n","anal\n","isti\n","bank\n","acılar\n","anal\n","isti\n","büyük\n","ölçekte\n","veri\n","karşısında\n","zor\n","landı\n","lar\n","bank\n","acı\n","bank\n","acı\n","anal\n","isti\n","bank\n","acı\n","anal\n","isti\n","büyük\n","ölçekte\n","veri\n","karşısında\n","zor\n","landı\n","lar\n","yazılım\n","cının\n","yazılım\n","cının\n","direktör\n","leri\n","yazılım\n","cının\n","direktör\n","leri\n","daha\n","etkili\n","bir\n","özet\n","yaz\n","dılar\n","yazılım\n","cıların\n","yazılım\n","cıların\n","direktörü\n","yazılım\n","cıların\n","direktörü\n","daha\n","etkili\n","bir\n","özet\n","yaz\n","dılar\n","yazılım\n","cının\n","yazılım\n","cının\n","direktörü\n","yazılım\n","cının\n","direktörü\n","daha\n","etkili\n","bir\n","özet\n","yaz\n","dılar\n","yazılım\n","cı\n","yazılım\n","cı\n","direktör\n","leri\n","yazılım\n","cı\n","direktör\n","leri\n","daha\n","etkili\n","bir\n","özet\n","yaz\n","dılar\n","yazılım\n","cılar\n","yazılım\n","cılar\n","direktörü\n","yazılım\n","cılar\n","direktörü\n","daha\n","etkili\n","bir\n","özet\n","yaz\n","dılar\n","yazılım\n","cı\n","yazılım\n","cı\n","direktörü\n","yazılım\n","cı\n","direktörü\n","daha\n","etkili\n","bir\n","özet\n","yaz\n","dılar\n","i̇ş\n","çinin\n","i̇ş\n","çinin\n","\n","denet\n","çileri\n","i̇ş\n","çinin\n","\n","denet\n","çileri\n","tüm\n","\n","üretim\n","\n","aşamasını\n","dikkatle\n","izl\n","ediler\n","i̇ş\n","çilerin\n","i̇ş\n","çilerin\n","denet\n","çisi\n","i̇ş\n","çilerin\n","denet\n","çisi\n","tüm\n","\n","üretim\n","\n","aşamasını\n","dikkatle\n","izl\n","ediler\n","i̇ş\n","çinin\n","i̇ş\n","çinin\n","\n","denet\n","çisi\n","i̇ş\n","çinin\n","\n","denet\n","çisi\n","tüm\n","\n","üretim\n","\n","aşamasını\n","dikkatle\n","izl\n","ediler\n","i̇şçi\n","i̇şçi\n","denet\n","çileri\n","i̇şçi\n","denet\n","çileri\n","tüm\n","\n","üretim\n","\n","aşamasını\n","dikkatle\n","izl\n","ediler\n","i̇ş\n","çiler\n","i̇ş\n","çiler\n","denet\n","çisi\n","i̇ş\n","çiler\n","denet\n","çisi\n","tüm\n","\n","üretim\n","\n","aşamasını\n","dikkatle\n","izl\n","ediler\n","i̇şçi\n","i̇şçi\n","denet\n","çisi\n","i̇şçi\n","denet\n","çisi\n","tüm\n","\n","üretim\n","\n","aşamasını\n","dikkatle\n","izl\n","ediler\n","engel\n","linin\n","engel\n","linin\n","savunucu\n","ları\n","engel\n","linin\n","savunucu\n","ları\n","yeni\n","bildir\n","g\n","eyi\n","yüksek\n","sesle\n","okudu\n","lar\n","engel\n","lilerin\n","engel\n","lilerin\n","savunucusu\n","engel\n","lilerin\n","savunucusu\n","yeni\n","bildir\n","g\n","eyi\n","yüksek\n","sesle\n","okudu\n","lar\n","engel\n","linin\n","engel\n","linin\n","savunucusu\n","engel\n","linin\n","savunucusu\n","yeni\n","bildir\n","g\n","eyi\n","yüksek\n","sesle\n","okudu\n","lar\n","engelli\n","engelli\n","savunucu\n","ları\n","engelli\n","savunucu\n","ları\n","yeni\n","bildir\n","g\n","eyi\n","yüksek\n","sesle\n","okudu\n","lar\n","engel\n","liler\n","engel\n","liler\n","savunucusu\n","engel\n","liler\n","savunucusu\n","yeni\n","bildir\n","g\n","eyi\n","yüksek\n","sesle\n","okudu\n","lar\n","engelli\n","engelli\n","savunucusu\n","engelli\n","savunucusu\n","yeni\n","bildir\n","g\n","eyi\n","yüksek\n","sesle\n","okudu\n","lar\n","p\n","erson\n","elin\n","p\n","erson\n","elin\n","mü\n","fett\n","işleri\n","p\n","erson\n","elin\n","mü\n","fett\n","işleri\n","işyer\n","indeki\n","der\n","li\n","toplu\n","sistemi\n","beğend\n","iler\n","personel\n","lerin\n","personel\n","lerin\n","mü\n","fett\n","işi\n","personel\n","lerin\n","mü\n","fett\n","işi\n","işyer\n","indeki\n","der\n","li\n","toplu\n","sistemi\n","beğend\n","iler\n","p\n","erson\n","elin\n","p\n","erson\n","elin\n","mü\n","fett\n","işi\n","p\n","erson\n","elin\n","mü\n","fett\n","işi\n","işyer\n","indeki\n","der\n","li\n","toplu\n","sistemi\n","beğend\n","iler\n","personel\n","personel\n","mü\n","fett\n","işleri\n","personel\n","mü\n","fett\n","işleri\n","işyer\n","indeki\n","der\n","li\n","toplu\n","sistemi\n","beğend\n","iler\n","p\n","erson\n","eller\n","p\n","erson\n","eller\n","mü\n","fett\n","işi\n","p\n","erson\n","eller\n","mü\n","fett\n","işi\n","işyer\n","indeki\n","der\n","li\n","toplu\n","sistemi\n","beğend\n","iler\n","personel\n","personel\n","mü\n","fett\n","işi\n","personel\n","mü\n","fett\n","işi\n","işyer\n","indeki\n","der\n","li\n","toplu\n","sistemi\n","beğend\n","iler\n","kir\n","acının\n","kir\n","acının\n","arabulu\n","cuları\n","kir\n","acının\n","arabulu\n","cuları\n","hafta\n","boyu\n","sözleşme\n","için\n","çalıştılar\n","kir\n","acıların\n","kir\n","acıların\n","arabulu\n","cusu\n","kir\n","acıların\n","arabulu\n","cusu\n","hafta\n","boyu\n","sözleşme\n","için\n","çalıştılar\n","kir\n","acının\n","kir\n","acının\n","arabulu\n","cusu\n","kir\n","acının\n","arabulu\n","cusu\n","hafta\n","boyu\n","sözleşme\n","için\n","çalıştılar\n","kir\n","acı\n","kir\n","acı\n","arabulu\n","cuları\n","kir\n","acı\n","arabulu\n","cuları\n","hafta\n","boyu\n","sözleşme\n","için\n","çalıştılar\n","kir\n","acılar\n","kir\n","acılar\n","arabulu\n","cusu\n","kir\n","acılar\n","arabulu\n","cusu\n","hafta\n","boyu\n","sözleşme\n","için\n","çalıştılar\n","kir\n","acı\n","kir\n","acı\n","arabulu\n","cusu\n","kir\n","acı\n","arabulu\n","cusu\n","hafta\n","boyu\n","sözleşme\n","için\n","çalıştılar\n","                                              sentence  attention_to_head  \\\n","0    Göçmenin sözcüleri geçen hafta protestoda aral...           0.037333   \n","1    Göçmenlerin sözcüsü geçen hafta protestoda ara...           0.039690   \n","2    Göçmenin sözcüsü geçen hafta protestoda aralık...           0.021906   \n","3    Göçmen sözcüleri geçen hafta protestoda aralık...           0.040070   \n","4    Göçmenler sözcüsü geçen hafta protestoda aralı...           0.027003   \n","..                                                 ...                ...   \n","139  Kiracıların arabulucusu hafta boyu sözleşme iç...           0.082274   \n","140  Kiracının arabulucusu hafta boyu sözleşme için...           0.080091   \n","141  Kiracı arabulucuları hafta boyu sözleşme için ...           0.030572   \n","142  Kiracılar arabulucusu hafta boyu sözleşme için...           0.062716   \n","143  Kiracı arabulucusu hafta boyu sözleşme için ça...           0.053023   \n","\n","     attention_to_attractor  \n","0                  1.050090  \n","1                  1.040774  \n","2                  1.094631  \n","3                  1.006234  \n","4                  1.037679  \n","..                      ...  \n","139                0.583690  \n","140                0.588158  \n","141                0.637066  \n","142                0.594458  \n","143                0.599793  \n","\n","[144 rows x 3 columns]\n"]},{"ename":"PermissionError","evalue":"[Errno 13] Permission denied: 'turkish_gpt2_attention_output.csv'","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m turkish_gpt2_df = extract_attention_from_df(df)\n\u001b[32m     92\u001b[39m \u001b[38;5;28mprint\u001b[39m(turkish_gpt2_df[[\u001b[33m\"\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_to_head\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_to_attractor\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mturkish_gpt2_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mturkish_gpt2_attention_output.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n","\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'turkish_gpt2_attention_output.csv'"]}],"source":["model_name = \"ytu-ce-cosmos/turkish-gpt2\"\n","\n","config = AutoConfig.from_pretrained(model_name)\n","config.output_attentions = True\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","model = AutoModelForCausalLM.from_pretrained(model_name, config=config)\n","model.eval()\n","\n","df = pd.read_csv(\"target_model_input.csv\")\n","\n","def find_token_span(word, tokens):\n","    word = word.lower().strip(\".,’'\")\n","    word_pointer = 0\n","    indices = []\n","    buffer = \"\"\n","\n","    for i, tok in enumerate(tokens):\n","        tok_str = tokenizer.convert_tokens_to_string([tok]).strip().lower()\n","\n","        # Fix corrupted chars\n","        #tok_str = (tok_str\n","        #           .replace(\"â\", \"ı\")\n","        #           .replace(\"Ã§\", \"ç\")\n","        #           .replace(\"Å\", \"ş\")\n","        #           .replace(\"Ä±\", \"ı\")\n","        #           .replace(\"Ġ\", \"\")\n","        #           .replace(\"##\", \"\"))\n","        buffer += tok_str\n","        indices.append(i)\n","        print(tok_str)\n","        if buffer.startswith(word):\n","            if len(buffer) >= len(word):\n","                return indices\n","        elif not word.startswith(buffer):\n","            buffer = \"\"\n","            indices = []\n","    return []\n","\n","def extract_attention_from_df(df, layer=GPT2_LAYER, head=GPT2_HEAD):\n","    rows = []\n","\n","    for _, row in df.iterrows():\n","        sentence = row[\"Sentence\"]\n","        words = sentence.strip(\".\").split()\n","        if len(words) < 3:\n","            print(f\"[SKIP] Too short: {sentence}\")\n","            continue\n","\n","        attractor = words[0]\n","        head_word = words[1]\n","        verb = words[-1]\n","\n","        # Tokenize\n","        inputs = tokenizer(sentence, return_tensors=\"pt\")\n","        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n","\n","        attractor_span = find_token_span(attractor, tokens)\n","        head_span = find_token_span(head_word, tokens)\n","        verb_span = find_token_span(verb, tokens)\n","\n","        if not attractor_span or not head_span or not verb_span:\n","            print(f\"[SKIP] No span found in: {sentence}\")\n","            continue\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs, output_attentions=True)\n","            attn = outputs.attentions[layer][0, head]  # [seq, seq]\n","\n","        attn_to_attr = attn[verb_span][:, attractor_span].sum().item()\n","        attn_to_head = attn[verb_span][:, head_span].sum().item()\n","\n","        rows.append({\n","            \"item\": row[\"Item\"],\n","            \"sentence\": sentence,\n","            \"case\": row[\"Case\"],\n","            \"number\": row[\"Number\"],\n","            #\"head_num\": row[\"head_num\"],\n","            #\"attr_num\": row[\"attr_num\"],\n","            #\"verb_num\": row[\"verb_num\"],\n","            \"attention_to_attractor\": attn_to_attr,\n","            \"attention_to_head\": attn_to_head,\n","            \"attractor_tokens\": [tokens[i] for i in attractor_span],\n","            \"head_tokens\": [tokens[i] for i in head_span],\n","            \"verb_tokens\": [tokens[i] for i in verb_span],\n","        })\n","\n","    return pd.DataFrame(rows)\n","\n","turkish_gpt2_df = extract_attention_from_df(df)\n","print(turkish_gpt2_df[[\"sentence\", \"attention_to_head\", \"attention_to_attractor\"]])\n","\n","turkish_gpt2_df.to_csv(\"turkish_gpt2_attention_output.csv\", index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"AXLVeyvQmUnA"},"source":["## PLOT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evhk4-eomUnB","outputId":"bc4a613a-2991-417c-b194-98b249affe41"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 800x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","df = pd.read_csv(\"turkish_gpt2_attention_output.csv\")\n","\n","# Compute mean + SE for Case × Number\n","stats = df.groupby([\"case\", \"number\"])[\"attention_diff\"].agg([\"mean\", \"sem\"]).reset_index()\n","\n","cases = stats[\"case\"].unique()\n","numbers = stats[\"number\"].unique()\n","\n","# x positions for each case\n","x = np.arange(len(cases))\n","\n","# dodge width\n","dodge = 0.15\n","\n","plt.figure(figsize=(8,5))\n","\n","for i, num in enumerate(numbers):\n","    sub = stats[stats[\"number\"] == num]\n","\n","    # Shift x positions for dodging\n","    x_positions = x + (i - (len(numbers)-1)/2) * dodge\n","\n","    plt.errorbar(\n","        x_positions,\n","        sub[\"mean\"],\n","        yerr=sub[\"sem\"],\n","        fmt=\"o\",\n","        capsize=4,\n","        label=f\"{num}\"\n","    )\n","\n","plt.xticks(x, cases)\n","plt.xlabel(\"Case\")\n","plt.ylabel(\"Att. to Attr. - Att. to Head\")\n","plt.title(\"Attention Difference by Case × Number (GPT2)\")\n","plt.legend(title=\"Number\")\n","plt.grid(alpha=0.2)\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"5MkzgLtAmUnB"},"source":["## BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614,"referenced_widgets":["b6cb1d566a5049c882e4670ab25ebae3","f9c41822ecc944398483fae47a2ecdef","4d59117d45134d0097f0a356918436c3","e510c24afc72433e8414b5d2dddad5ac","d297426dcb474ff398c2d6f56588478c","8c8adb3c7c8f44a1861d2873507ee344","6dc43c890b3f4648a6ab5925523899a2","4d097531f03a4b03b2361809028c706f","40450b9fb99448ffadb61c10cd5f6743","654ce866c7df4f0c9b45db2b601daec8","d70b3d8a6e0f4c93a015877a151c3206","a1dc525700aa4e83b5728fb674430606","2422cf93823b43ebb6111f3143be4b44","37d0eded7631426eaba755befa2a3881","f106c9bea09c451988501069b53bc373","67bd45f58feb47f6a4c59863282a463e","3e5506e3f9da43ea8bf4d271a9b53c75","b7cdbd439c2d4cffa6103430eeab077c","e6d4a3bb404540b7ae1126ada3a85756","cbdf4d46c91841a58a2268ad926badb7","51aad787fdf44617b6ff49372221a035","d7e2ba157ba34208aa5766fa037137ec","f08ecb4189854aec9b034f885931ee44","109fcd8765bb4d3eae93b1b9c06cb845","d98c90eaf0944222be7b9bb930c19944","11e116be133f4444b4a3fd7a2a770bff","fde3d4e4ce074fdd9ad86fcdfc9ba4c8","c39694cde068499387c8c975b0e565b4","de86eb6fc9e1480fb6a5e31fca3fd6c8","18446baf0ce1423b8a477628aa3747be","82a4d38b95e44299954bce7c33b19426","74c401a754b34674840412c6d67580f9","84c1ca5e418046f5a81f3b72d34551f6","c01305e1ea4045d7980ba79665e8e2aa","be586421c5a84e5682d70390169f9345","a5c1a027b82c42968d78a6eed66ca6a7","df718f4d3ab54ea08da3cd0c7a4ecec7","f62cb2d34fb54683b44adeb6869571c8","e7dbc4c5762142faba79b1b2d6a82592","e69d547162704477a4b1f118cbce4995","102cd36ba2934791a612ae23b8c74a98","f8f5ed4c1af1431e852556fac59b9608","c641e76015b741149a08bbd1c1308a84","e30c2b963f6c4c29a141fe9b6113bed6"]},"id":"4K9p9TyZ7W-7","outputId":"f5b26d78-2f88-4f5b-91a7-a0c9f4fca574"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[31m---------------------------------------------------------------------------\u001b[39m","\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     58\u001b[39m         rows.append({\n\u001b[32m     59\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mitem\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mItem\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     60\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m\"\u001b[39m: sentence,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverb_tokens\u001b[39m\u001b[33m\"\u001b[39m: [tokens[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m verb_span],\n\u001b[32m     71\u001b[39m         })\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(rows)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m turkish_bert_df = \u001b[43mextract_bert_attention_from_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(turkish_bert_df[[\u001b[33m\"\u001b[39m\u001b[33msentence\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_to_attractor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_to_head\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m     78\u001b[39m turkish_bert_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33mturkish_bert_attention_verb_to_nouns.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mextract_bert_attention_from_df\u001b[39m\u001b[34m(df, layer, attn_head)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     attentions = outputs.attentions \n\u001b[32m     53\u001b[39m attn_matrix = attentions[layer][\u001b[32m0\u001b[39m, attn_head]  \n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1000\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    996\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    998\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1014\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:650\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    646\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    648\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m650\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:558\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    548\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    556\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    557\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    567\u001b[39m     outputs = self_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:488\u001b[39m, in \u001b[36mBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;129m@deprecate_kwarg\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpast_key_value\u001b[39m\u001b[33m\"\u001b[39m, new_name=\u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m4.58\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    486\u001b[39m     cache_position: Optional[torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    487\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    498\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:255\u001b[39m, in \u001b[36mBertSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    253\u001b[39m     value_layer = curr_past_key_value.layers[\u001b[38;5;28mself\u001b[39m.layer_idx].values\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     key_layer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     key_layer = key_layer.view(batch_size, -\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_attention_heads, \u001b[38;5;28mself\u001b[39m.attention_head_size).transpose(\n\u001b[32m    257\u001b[39m         \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m\n\u001b[32m    258\u001b[39m     )\n\u001b[32m    259\u001b[39m     value_layer = \u001b[38;5;28mself\u001b[39m.value(current_states)\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n","\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[31mKeyboardInterrupt\u001b[39m: "]}],"source":["model_name = \"dbmdz/bert-base-turkish-cased\"\n","config = AutoConfig.from_pretrained(model_name)\n","config.output_attentions = True\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name, config=config)\n","model.eval()\n","\n","df = pd.read_csv(\"target_model_input.csv\")\n","\n","def get_token_span(word, tokens):\n","    word = word.lower().strip(\".,’'\")\n","    span = []\n","    pointer = 0\n","    for i, token in enumerate(tokens):\n","        clean = token.replace(\"##\", \"\").lower().lstrip(\"▁\")\n","        if word[pointer:].startswith(clean):\n","            span.append(i)\n","            pointer += len(clean)\n","        if pointer >= len(word):\n","            break\n","    return span\n","\n","def extract_bert_attention_from_df(df, layer=BERT_LAYER, attn_head=BERT_HEAD):\n","    rows = []\n","\n","    for _, row in df.iterrows():\n","        sentence = row[\"Sentence\"]\n","        words = sentence.strip(\".\").split()\n","        if len(words) < 3:\n","            print(f\"[SKIP] Too short: {sentence}\")\n","            continue\n","\n","        attractor = words[0]\n","        head = words[1]\n","        verb = words[-1]\n","\n","        inputs = tokenizer(sentence, return_tensors=\"pt\")\n","        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n","\n","        att_span = get_token_span(attractor, tokens)\n","        head_span = get_token_span(head, tokens)\n","        verb_span = get_token_span(verb, tokens)\n","\n","        if not att_span or not head_span or not verb_span:\n","            print(f\"[SKIP] No span found in: {sentence}\")\n","            continue\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs, output_attentions=True)\n","            attentions = outputs.attentions\n","\n","        attn_matrix = attentions[layer][0, attn_head]\n","\n","        attn_to_att = attn_matrix[verb_span][:, att_span].sum().item()\n","        attn_to_head = attn_matrix[verb_span][:, head_span].sum().item()\n","\n","        rows.append({\n","            \"item\": row[\"Item\"],\n","            \"sentence\": sentence,\n","            \"case\": row[\"Case\"],\n","            \"number\": row[\"Number\"],\n","            #\"head_num\": row[\"head_num\"],\n","            #\"attr_num\": row[\"attr_num\"],\n","            #\"verb_num\": row[\"verb_num\"],\n","            \"attention_to_attractor\": attn_to_att,\n","            \"attention_to_head\": attn_to_head,\n","            \"attractor_tokens\": [tokens[i] for i in att_span],\n","            \"head_tokens\": [tokens[i] for i in head_span],\n","            \"verb_tokens\": [tokens[i] for i in verb_span],\n","        })\n","\n","    return pd.DataFrame(rows)\n","\n","turkish_bert_df = extract_bert_attention_from_df(df)\n","print(turkish_bert_df[[\"sentence\", \"attention_to_attractor\", \"attention_to_head\"]])\n","\n","turkish_bert_df.to_csv(\"turkish_bert_attention_verb_to_nouns.csv\", index=False)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jc0IMRiymUnB","executionInfo":{"status":"error","timestamp":1765560439801,"user_tz":300,"elapsed":1523,"user":{"displayName":"Utku Turk","userId":"12980072148078189927"}},"outputId":"c340e973-7c3c-4cc8-f686-1c31dce08f5a","colab":{"base_uri":"https://localhost:8080/","height":394}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'turkish_bert_attention_verb_to_nouns.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-910219359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"turkish_bert_attention_verb_to_nouns.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Compute mean + SE for Case × Number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"case\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"number\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_diff\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sem\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'turkish_bert_attention_verb_to_nouns.csv'"]}],"source":["import pandas as pd\n","df = pd.read_csv(\"turkish_bert_attention_verb_to_nouns.csv\")\n","\n","# Compute mean + SE for Case × Number\n","stats = df.groupby([\"case\", \"number\"])[\"attention_diff\"].agg([\"mean\", \"sem\"]).reset_index()\n","\n","cases = stats[\"case\"].unique()\n","numbers = stats[\"number\"].unique()\n","\n","# x positions for each case\n","x = np.arange(len(cases))\n","\n","# dodge width\n","dodge = 0.15\n","\n","plt.figure(figsize=(8,5))\n","\n","for i, num in enumerate(numbers):\n","    sub = stats[stats[\"number\"] == num]\n","\n","    # Shift x positions for dodging\n","    x_positions = x + (i - (len(numbers)-1)/2) * dodge\n","\n","    plt.errorbar(\n","        x_positions,\n","        sub[\"mean\"],\n","        yerr=sub[\"sem\"],\n","        fmt=\"o\",\n","        capsize=4,\n","        label=f\"{num}\"\n","    )\n","\n","plt.xticks(x, cases)\n","plt.xlabel(\"Case\")\n","plt.ylabel(\"Att. to Attr. - Att. to Head\")\n","plt.title(\"Attention Difference by Case × Number (BERT)\")\n","plt.legend(title=\"Number\")\n","plt.grid(alpha=0.2)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6T4t16gs-xND","outputId":"926d795f-7359-4523-b0f3-446fae206acc"},"outputs":[{"name":"stdout","output_type":"stream","text":["    item                                           sentence    condition  \\\n","0      1   yöneticilerin aşçısı mutfakta sürekli zıpladılar  condition_a   \n","1      1      yöneticilerin aşçısı mutfakta sürekli zıpladı  condition_b   \n","2      1     yöneticinin aşçısı mutfakta sürekli zıpladılar  condition_c   \n","3      1        yöneticinin aşçısı mutfakta sürekli zıpladı  condition_d   \n","4      2      öğrencilerin ablası sınıfta birden bayıldılar  condition_a   \n","..   ...                                                ...          ...   \n","615   37  Politikacının tercümanı toplantıdan sonra bird...  condition_d   \n","616   38  Mühendislerin işvereni yabancı bir ülkede kayb...  condition_a   \n","617   38  Mühendislerin işvereni yabancı bir ülkede kayb...  condition_b   \n","618   38  Mühendisin işvereni yabancı bir ülkede kaybold...  condition_c   \n","619   38    Mühendisin işvereni yabancı bir ülkede kayboldu  condition_d   \n","\n","    head_num attr_num verb_num  attention_to_attractor  attention_to_head  \\\n","0         sg       pl       pl                0.035185           0.053760   \n","1         sg       pl       sg                0.050856           0.049862   \n","2         sg       sg       pl                0.139017           0.049499   \n","3         sg       sg       sg                0.147774           0.049087   \n","4         sg       pl       pl                0.054836           0.126764   \n","..       ...      ...      ...                     ...                ...   \n","615       sg       sg       sg                1.939120           0.004431   \n","616       sg       pl       pl                1.742301           0.004966   \n","617       sg       pl       sg                0.784520           0.002120   \n","618       sg       sg       pl                1.688243           0.004444   \n","619       sg       sg       sg                0.763217           0.001842   \n","\n","    model  \n","0    bert  \n","1    bert  \n","2    bert  \n","3    bert  \n","4    bert  \n","..    ...  \n","615  gpt2  \n","616  gpt2  \n","617  gpt2  \n","618  gpt2  \n","619  gpt2  \n","\n","[620 rows x 9 columns]\n"]}],"source":["bert_df = turkish_bert_df[[\"item\", \"sentence\", \"condition\", \"head_num\", \"attr_num\", \"verb_num\", \"attention_to_attractor\", \"attention_to_head\"]].copy()\n","bert_df[\"model\"] = \"bert\"\n","\n","gpt2_df_clean = turkish_gpt2_df[[\"item\", \"sentence\", \"condition\", \"head_num\", \"attr_num\", \"verb_num\", \"attention_to_attractor\", \"attention_to_head\"]].copy()\n","gpt2_df_clean[\"model\"] = \"gpt2\"\n","\n","combined_df = pd.concat([bert_df, gpt2_df_clean], ignore_index=True)\n","\n","print(combined_df)\n","combined_df.to_csv(\"combined_bert_gpt2_attention_turkish.csv\", index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"EmrWbEj6mUnC"},"source":["# Surprisal"]},{"cell_type":"markdown","metadata":{"id":"KAqcEU0GmUnC"},"source":["## BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKCkINDS_IID","outputId":"5282cd01-f4ea-4e3a-958f-aabc3a079dd5"},"outputs":[{"name":"stdout","output_type":"stream","text":["    item                                           sentence    condition  \\\n","0      1   yöneticilerin aşçısı mutfakta sürekli zıpladılar  condition_a   \n","1      1      yöneticilerin aşçısı mutfakta sürekli zıpladı  condition_b   \n","2      1     yöneticinin aşçısı mutfakta sürekli zıpladılar  condition_c   \n","3      1        yöneticinin aşçısı mutfakta sürekli zıpladı  condition_d   \n","4      2      öğrencilerin ablası sınıfta birden bayıldılar  condition_a   \n","..   ...                                                ...          ...   \n","307   37  Politikacının tercümanı toplantıdan sonra bird...  condition_d   \n","308   38  Mühendislerin işvereni yabancı bir ülkede kayb...  condition_a   \n","309   38  Mühendislerin işvereni yabancı bir ülkede kayb...  condition_b   \n","310   38  Mühendisin işvereni yabancı bir ülkede kaybold...  condition_c   \n","311   38    Mühendisin işvereni yabancı bir ülkede kayboldu  condition_d   \n","\n","    head_num attr_num verb_num         verb  surprisal model  \n","0         sg       pl       pl   zıpladılar  10.240043  bert  \n","1         sg       pl       sg      zıpladı  10.240043  bert  \n","2         sg       sg       pl   zıpladılar   9.902610  bert  \n","3         sg       sg       sg      zıpladı   9.902610  bert  \n","4         sg       pl       pl   bayıldılar   9.390772  bert  \n","..       ...      ...      ...          ...        ...   ...  \n","307       sg       sg       sg      sarardı  10.267175  bert  \n","308       sg       pl       pl  kayboldular  14.245720  bert  \n","309       sg       pl       sg     kayboldu  18.893894  bert  \n","310       sg       sg       pl  kayboldular  12.767754  bert  \n","311       sg       sg       sg     kayboldu  17.980671  bert  \n","\n","[312 rows x 9 columns]\n"]}],"source":["model_name = \"dbmdz/bert-base-turkish-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForMaskedLM.from_pretrained(model_name)\n","model.eval()\n","\n","df = pd.read_csv(\"syn_llm.csv\", header=None,\n","    names=[\"language\", \"item\", \"syncretic\", \"sentence\", \"condition\", \"head_num\", \"attr_num\", \"verb_num\"])\n","df = df[df[\"language\"] == \"turkish\"]\n","\n","results = []\n","\n","for _, row in df.iterrows():\n","    sentence = row[\"sentence\"]\n","    words = sentence.strip(\".\").split()\n","    if len(words) < 3:\n","        print(f\"[SKIP] Too short: {sentence}\")\n","        continue\n","\n","    verb = words[-1]\n","    masked_words = words[:-1] + [\"[MASK]\"]\n","    masked_sent = \" \".join(masked_words)\n","\n","    try:\n","        inputs = tokenizer(masked_sent, return_tensors=\"pt\")\n","        mask_idx = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=True)[1].item()\n","\n","        with torch.no_grad():\n","            logits = model(**inputs).logits  # [batch, seq, vocab]\n","\n","        probs = F.softmax(logits, dim=-1)\n","        verb_id = tokenizer.convert_tokens_to_ids(verb)\n","        prob = probs[0, mask_idx, verb_id].item()\n","\n","        surprisal = -torch.log2(torch.tensor(prob)).item()\n","\n","        results.append({\n","            \"item\": row[\"item\"],\n","            \"sentence\": sentence,\n","            \"condition\": row[\"condition\"],\n","            \"head_num\": row[\"head_num\"],\n","            \"attr_num\": row[\"attr_num\"],\n","            \"verb_num\": row[\"verb_num\"],\n","            \"verb\": verb,\n","            \"surprisal\": surprisal,\n","            \"model\": \"bert\"\n","        })\n","\n","    except Exception as e:\n","        print(f\"[SKIP] {sentence} — {e}\")\n","        continue\n","\n","bert_surprisal_df = pd.DataFrame(results)\n","print(bert_surprisal_df)\n","\n","bert_surprisal_df.to_csv(\"bert_turkish_verb_surprisal.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"8G-C0d8nmUnC"},"source":["## GPT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALJ3Y6-AAo56","outputId":"50e57002-3a84-4420-c8a5-9093e8ad0809"},"outputs":[{"name":"stdout","output_type":"stream","text":["    item                                           sentence    condition  \\\n","0      1   yöneticilerin aşçısı mutfakta sürekli zıpladılar  condition_a   \n","1      1      yöneticilerin aşçısı mutfakta sürekli zıpladı  condition_b   \n","2      1     yöneticinin aşçısı mutfakta sürekli zıpladılar  condition_c   \n","3      1        yöneticinin aşçısı mutfakta sürekli zıpladı  condition_d   \n","4      2      öğrencilerin ablası sınıfta birden bayıldılar  condition_a   \n","..   ...                                                ...          ...   \n","307   37  Politikacının tercümanı toplantıdan sonra bird...  condition_d   \n","308   38  Mühendislerin işvereni yabancı bir ülkede kayb...  condition_a   \n","309   38  Mühendislerin işvereni yabancı bir ülkede kayb...  condition_b   \n","310   38  Mühendisin işvereni yabancı bir ülkede kaybold...  condition_c   \n","311   38    Mühendisin işvereni yabancı bir ülkede kayboldu  condition_d   \n","\n","    head_num attr_num verb_num      token  surprisal model  \n","0         sg       pl       pl   ladÄ±lar  11.886078  gpt2  \n","1         sg       pl       sg      ladÄ±   5.867414  gpt2  \n","2         sg       sg       pl   ladÄ±lar  13.834587  gpt2  \n","3         sg       sg       sg      ladÄ±   6.145100  gpt2  \n","4         sg       pl       pl        lar   6.554229  gpt2  \n","..       ...      ...      ...        ...        ...   ...  \n","307       sg       sg       sg      ardÄ±   7.886008  gpt2  \n","308       sg       pl       pl      dular   7.530234  gpt2  \n","309       sg       pl       sg  Ġkayboldu  18.885220  gpt2  \n","310       sg       sg       pl      dular   9.861742  gpt2  \n","311       sg       sg       sg  Ġkayboldu  17.624777  gpt2  \n","\n","[312 rows x 9 columns]\n"]}],"source":["model_name = \"ytu-ce-cosmos/turkish-gpt2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","model.eval()\n","\n","df = pd.read_csv(\"syn_llm.csv\", header=None,\n","    names=[\"language\", \"item\", \"syncretic\", \"sentence\", \"condition\", \"head_num\", \"attr_num\", \"verb_num\"])\n","df = df[df[\"language\"] == \"turkish\"]\n","\n","results = []\n","\n","for _, row in df.iterrows():\n","    sentence = row[\"sentence\"]\n","    try:\n","        # Tokenize\n","        inputs = tokenizer(sentence, return_tensors=\"pt\")\n","        input_ids = inputs[\"input_ids\"]\n","\n","        with torch.no_grad():\n","            logits = model(**inputs).logits\n","\n","        probs = F.softmax(logits, dim=-1)\n","        next_token_probs = probs[0, :-1, :]\n","        true_next_tokens = input_ids[0, 1:]\n","\n","        surprisals = -torch.log2(next_token_probs[torch.arange(len(true_next_tokens)), true_next_tokens])\n","\n","        tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n","\n","        for tok, s in reversed(list(zip(tokens[1:], surprisals.tolist()))):\n","            clean = tok.replace(\"Ġ\", \"\").replace(\"▁\", \"\").strip().lower()\n","            if clean and clean not in [\".\", \",\", \";\", \"!\", \"?\"]:\n","                results.append({\n","                    \"item\": row[\"item\"],\n","                    \"sentence\": sentence,\n","                    \"condition\": row[\"condition\"],\n","                    \"head_num\": row[\"head_num\"],\n","                    \"attr_num\": row[\"attr_num\"],\n","                    \"verb_num\": row[\"verb_num\"],\n","                    \"token\": tok,\n","                    \"surprisal\": s,\n","                    \"model\": \"gpt2\"\n","                })\n","                break\n","        else:\n","            print(f\"[SKIP] No content token found: {sentence}\")\n","\n","    except Exception as e:\n","        print(f\"[SKIP] {sentence} — {e}\")\n","        continue\n","\n","gpt2_surprisal_df = pd.DataFrame(results)\n","print(gpt2_surprisal_df)\n","\n","gpt2_surprisal_df.to_csv(\"gpt2_turkish_verb_surprisal.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ENXDLB_uCD4O"},"outputs":[],"source":["import numpy as np\n","\n","bert_surprisal_df[\"surprisal\"] = bert_surprisal_df[\"surprisal\"] / np.log(2)\n","gpt2_surprisal_df[\"surprisal\"] = -gpt2_surprisal_df[\"surprisal\"]\n","gpt2_surprisal_df[\"surprisal\"] = gpt2_surprisal_df[\"surprisal\"] / np.log(2)\n","surp_combined_df = pd.concat([bert_surprisal_df, gpt2_surprisal_df], ignore_index=True)\n","surp_combined_df.to_csv(\"turkish_bert_gpt2_combined_surprisal.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01ae6b1e92fe4296b33bdcd03a253f65":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fa803c042f14271865de166e3d56ac0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efa9d48345ba406cb801c5c967897141","max":60,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1fb76f1bed76497a8dace8c550e8f8e0","value":60}},"102cd36ba2934791a612ae23b8c74a98":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"109fcd8765bb4d3eae93b1b9c06cb845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c39694cde068499387c8c975b0e565b4","placeholder":"​","style":"IPY_MODEL_de86eb6fc9e1480fb6a5e31fca3fd6c8","value":"vocab.txt: 100%"}},"11e116be133f4444b4a3fd7a2a770bff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74c401a754b34674840412c6d67580f9","placeholder":"​","style":"IPY_MODEL_84c1ca5e418046f5a81f3b72d34551f6","value":" 251k/251k [00:00&lt;00:00, 2.00MB/s]"}},"134334776a3e482bac49ffe97afa431c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18446baf0ce1423b8a477628aa3747be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a803b3bff2049bb8351e780bfa0887b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fb76f1bed76497a8dace8c550e8f8e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2422cf93823b43ebb6111f3143be4b44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e5506e3f9da43ea8bf4d271a9b53c75","placeholder":"​","style":"IPY_MODEL_b7cdbd439c2d4cffa6103430eeab077c","value":"tokenizer_config.json: 100%"}},"27e71a54bfe2418792952b481b5193ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e0ceb260f90492eab5d90fad20577ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32163483a005491b95ec2cbbb7492c9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2519c7f49374f8bbfcacb216f2c297c","placeholder":"​","style":"IPY_MODEL_134334776a3e482bac49ffe97afa431c","value":" 60.0/60.0 [00:00&lt;00:00, 6.37kB/s]"}},"371d0b936b1847c5b80f53e7b2c34414":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a803b3bff2049bb8351e780bfa0887b","placeholder":"​","style":"IPY_MODEL_27e71a54bfe2418792952b481b5193ee","value":" 740M/740M [00:16&lt;00:00, 87.0MB/s]"}},"37d0eded7631426eaba755befa2a3881":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6d4a3bb404540b7ae1126ada3a85756","max":60,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbdf4d46c91841a58a2268ad926badb7","value":60}},"3852516f93684934809fb0023a47920d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60f3dafbd12e47d1837da71b2aa825ff","IPY_MODEL_5e26958221d84b7486573d70b8e240cd","IPY_MODEL_3bf0346db9d341a99df3aadec7ddb419"],"layout":"IPY_MODEL_2e0ceb260f90492eab5d90fad20577ce"}},"3bf0346db9d341a99df3aadec7ddb419":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70175c3af1a844038a8977dadbba96e8","placeholder":"​","style":"IPY_MODEL_c6a8ad9b2fdf480da4c2deebf4f93f65","value":" 386/386 [00:00&lt;00:00, 45.8kB/s]"}},"3e5506e3f9da43ea8bf4d271a9b53c75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40450b9fb99448ffadb61c10cd5f6743":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40966579997846cf9460c09d2eabc649":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4172e6c05f364f21b272163eb4f7e673":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d097531f03a4b03b2361809028c706f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d59117d45134d0097f0a356918436c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d097531f03a4b03b2361809028c706f","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40450b9fb99448ffadb61c10cd5f6743","value":385}},"4fc815bd7ba2491cb3d699d610626b8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51aad787fdf44617b6ff49372221a035":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e26958221d84b7486573d70b8e240cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88e6592fb0ee440e8c040c75f9de2786","max":386,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f275096eb13b430fabda34c6775c4a10","value":386}},"60f3dafbd12e47d1837da71b2aa825ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_901cd23124c04d8999caca8b6ef5a76f","placeholder":"​","style":"IPY_MODEL_40966579997846cf9460c09d2eabc649","value":"config.json: 100%"}},"61ccef3824da4808a35e9a35a4a1578f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"647bc58a933a486ea19716726068c40c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"654ce866c7df4f0c9b45db2b601daec8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67bd45f58feb47f6a4c59863282a463e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c2d512ed0ca49048a51e40f621a57cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a131c1ebbee84fc5ab3c68eb10ae8772","max":740292264,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a68c7567b1cc430baa8274b0a77efb14","value":740292264}},"6dc43c890b3f4648a6ab5925523899a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70175c3af1a844038a8977dadbba96e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c401a754b34674840412c6d67580f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82a4d38b95e44299954bce7c33b19426":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84c1ca5e418046f5a81f3b72d34551f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"864b389ff32843109da6fbf7ee9d6446":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88e6592fb0ee440e8c040c75f9de2786":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89ee24ab36ab43819fa75d9ee4a94610":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc915ddbfe984e32b2d470d6721ca312","max":1176296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61ccef3824da4808a35e9a35a4a1578f","value":1176296}},"8c8adb3c7c8f44a1861d2873507ee344":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901cd23124c04d8999caca8b6ef5a76f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90ab314d128f4cb58037d5ea9349d74f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5d81ab61c414e33bc834914919cbda5","IPY_MODEL_6c2d512ed0ca49048a51e40f621a57cd","IPY_MODEL_371d0b936b1847c5b80f53e7b2c34414"],"layout":"IPY_MODEL_4172e6c05f364f21b272163eb4f7e673"}},"94a2e52eb0664c55a46bbd77fdf5cef8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95847a6792534459ad7cf1a57298bf8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0aec775e9b348a88fd6c10e1183f86c","IPY_MODEL_0fa803c042f14271865de166e3d56ac0","IPY_MODEL_32163483a005491b95ec2cbbb7492c9e"],"layout":"IPY_MODEL_c5d7881866a640dab1ed24cbc4795379"}},"a131c1ebbee84fc5ab3c68eb10ae8772":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1dc525700aa4e83b5728fb674430606":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2422cf93823b43ebb6111f3143be4b44","IPY_MODEL_37d0eded7631426eaba755befa2a3881","IPY_MODEL_f106c9bea09c451988501069b53bc373"],"layout":"IPY_MODEL_67bd45f58feb47f6a4c59863282a463e"}},"a5c1a027b82c42968d78a6eed66ca6a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_102cd36ba2934791a612ae23b8c74a98","max":444996256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8f5ed4c1af1431e852556fac59b9608","value":444996256}},"a68c7567b1cc430baa8274b0a77efb14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aea263246a2246109fb369b993f6d0c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c23ab283f3c14f4a81587a93e09c20d0","placeholder":"​","style":"IPY_MODEL_df10ad21684b4af0ae57cb931a2b3fbd","value":"vocab.txt: 100%"}},"aec17f62ae2e4070b35f5d9babdfe970":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_647bc58a933a486ea19716726068c40c","placeholder":"​","style":"IPY_MODEL_fc3f79eb1c92401e97b02ab9f24cf318","value":" 1.18M/1.18M [00:00&lt;00:00, 8.93MB/s]"}},"b0aec775e9b348a88fd6c10e1183f86c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a2e52eb0664c55a46bbd77fdf5cef8","placeholder":"​","style":"IPY_MODEL_864b389ff32843109da6fbf7ee9d6446","value":"tokenizer_config.json: 100%"}},"b6cb1d566a5049c882e4670ab25ebae3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9c41822ecc944398483fae47a2ecdef","IPY_MODEL_4d59117d45134d0097f0a356918436c3","IPY_MODEL_e510c24afc72433e8414b5d2dddad5ac"],"layout":"IPY_MODEL_d297426dcb474ff398c2d6f56588478c"}},"b7cdbd439c2d4cffa6103430eeab077c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be586421c5a84e5682d70390169f9345":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7dbc4c5762142faba79b1b2d6a82592","placeholder":"​","style":"IPY_MODEL_e69d547162704477a4b1f118cbce4995","value":"model.safetensors: 100%"}},"c01305e1ea4045d7980ba79665e8e2aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be586421c5a84e5682d70390169f9345","IPY_MODEL_a5c1a027b82c42968d78a6eed66ca6a7","IPY_MODEL_df718f4d3ab54ea08da3cd0c7a4ecec7"],"layout":"IPY_MODEL_f62cb2d34fb54683b44adeb6869571c8"}},"c23ab283f3c14f4a81587a93e09c20d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c308e926d7ff4065becddf30fec41f70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aea263246a2246109fb369b993f6d0c5","IPY_MODEL_89ee24ab36ab43819fa75d9ee4a94610","IPY_MODEL_aec17f62ae2e4070b35f5d9babdfe970"],"layout":"IPY_MODEL_01ae6b1e92fe4296b33bdcd03a253f65"}},"c39694cde068499387c8c975b0e565b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5d7881866a640dab1ed24cbc4795379":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c641e76015b741149a08bbd1c1308a84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a8ad9b2fdf480da4c2deebf4f93f65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbdf4d46c91841a58a2268ad926badb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2519c7f49374f8bbfcacb216f2c297c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d297426dcb474ff398c2d6f56588478c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d70b3d8a6e0f4c93a015877a151c3206":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7e2ba157ba34208aa5766fa037137ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98c90eaf0944222be7b9bb930c19944":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18446baf0ce1423b8a477628aa3747be","max":251003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82a4d38b95e44299954bce7c33b19426","value":251003}},"de86eb6fc9e1480fb6a5e31fca3fd6c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df10ad21684b4af0ae57cb931a2b3fbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df718f4d3ab54ea08da3cd0c7a4ecec7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c641e76015b741149a08bbd1c1308a84","placeholder":"​","style":"IPY_MODEL_e30c2b963f6c4c29a141fe9b6113bed6","value":" 445M/445M [00:06&lt;00:00, 122MB/s]"}},"e30c2b963f6c4c29a141fe9b6113bed6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e510c24afc72433e8414b5d2dddad5ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_654ce866c7df4f0c9b45db2b601daec8","placeholder":"​","style":"IPY_MODEL_d70b3d8a6e0f4c93a015877a151c3206","value":" 385/385 [00:00&lt;00:00, 41.1kB/s]"}},"e69d547162704477a4b1f118cbce4995":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6d4a3bb404540b7ae1126ada3a85756":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7dbc4c5762142faba79b1b2d6a82592":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efa9d48345ba406cb801c5c967897141":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f08ecb4189854aec9b034f885931ee44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_109fcd8765bb4d3eae93b1b9c06cb845","IPY_MODEL_d98c90eaf0944222be7b9bb930c19944","IPY_MODEL_11e116be133f4444b4a3fd7a2a770bff"],"layout":"IPY_MODEL_fde3d4e4ce074fdd9ad86fcdfc9ba4c8"}},"f106c9bea09c451988501069b53bc373":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51aad787fdf44617b6ff49372221a035","placeholder":"​","style":"IPY_MODEL_d7e2ba157ba34208aa5766fa037137ec","value":" 60.0/60.0 [00:00&lt;00:00, 4.23kB/s]"}},"f275096eb13b430fabda34c6775c4a10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f5d81ab61c414e33bc834914919cbda5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6745bf2bcd044aa93a6ae660826efba","placeholder":"​","style":"IPY_MODEL_4fc815bd7ba2491cb3d699d610626b8d","value":"model.safetensors: 100%"}},"f62cb2d34fb54683b44adeb6869571c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6745bf2bcd044aa93a6ae660826efba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8f5ed4c1af1431e852556fac59b9608":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9c41822ecc944398483fae47a2ecdef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c8adb3c7c8f44a1861d2873507ee344","placeholder":"​","style":"IPY_MODEL_6dc43c890b3f4648a6ab5925523899a2","value":"config.json: 100%"}},"fc3f79eb1c92401e97b02ab9f24cf318":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc915ddbfe984e32b2d470d6721ca312":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fde3d4e4ce074fdd9ad86fcdfc9ba4c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}